import requests
import re
import pandas as pd
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from datetime import datetime

# üîπ Klucz API do NewsAPI (UWAGA: Wstaw sw√≥j klucz API)
NEWS_API_KEY = "936e6ced8eec4858868ff737a86e3dcf"
analyzer = SentimentIntensityAnalyzer()

def clean_text(text):
    """Usuwa linki i znaki specjalne, normalizuje tekst"""
    text = re.sub(r'http\S+', '', text)  # Usu≈Ñ linki
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # Usu≈Ñ znaki specjalne
    return text.lower()

def fetch_news(news_topic):
    """Pobiera newsy dla danego tematu (np. 'crypto', 'forex', 'stocks')"""
    try:
        url = f"https://newsapi.org/v2/everything?q={news_topic}&language=en&sortBy=publishedAt&apiKey={NEWS_API_KEY}"
        response = requests.get(url, timeout=5)
        news_data = response.json()
        
        if response.status_code != 200 or "articles" not in news_data:
            print(f"‚ö†Ô∏è B≈ÇƒÖd API: {news_data.get('message', 'Nieznany b≈ÇƒÖd')}")
            return []
        
        return news_data["articles"][:10]  # Pobieramy 10 najnowszych news√≥w

    except requests.exceptions.RequestException as e:
        print(f"‚ùå B≈ÇƒÖd pobierania news√≥w: {e}")
        return []

def analyze_sentiment(news_articles):
    """Analizuje ≈õredni sentyment pobranych news√≥w"""
    sentiments = []
    weights = []
    now = datetime.utcnow()
    
    for i, article in enumerate(news_articles):
        text = clean_text(article["title"] + " " + article.get("description", ""))
        sentiment_score = analyzer.polarity_scores(text)['compound']  # Lepsza analiza ni≈º TextBlob

        # Pobranie daty publikacji newsa
        weight = 2.0 if i < 3 else 1.0  # Najnowsze newsy majƒÖ wiƒôkszy wp≈Çyw
        sentiments.append(sentiment_score * weight)
        weights.append(weight)

    if sentiments:
        avg_sentiment = sum(sentiments) / sum(weights)  # Normalizujemy wzglƒôdem wagi
        return round(avg_sentiment, 4)  # ZaokrƒÖglamy do 4 miejsc po przecinku

    return 0  # Neutralny sentyment

def load_assets_from_excel(file_path="assets_list.xlsx"):
    """Wczytuje symbole i kategorie z pliku Excel"""
    try:
        df = pd.read_excel(file_path)
        if "symbol" not in df.columns or "Kategoria" not in df.columns:
            print("‚ö†Ô∏è B≈ÇƒÖd: Excel musi zawieraƒá kolumny 'symbol' i 'Kategoria'.")
            return {}
        
        return dict(zip(df["symbol"], df["Kategoria"]))  # Tworzymy s≈Çownik {Symbol: Kategoria}
    
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd wczytywania pliku Excel: {e}")
        return {}

def get_sentiment_for_symbols():
    """Pobiera sentyment dla ka≈ºdego symbolu z Excela"""
    symbols_data = load_assets_from_excel()
    sentiment_dict = {}

    for symbol, category in symbols_data.items():
        sentiment = get_sentiment(category)
        sentiment_dict[symbol] = sentiment
        print(f"üìä AI Sentyment dla {symbol} ({category}): {sentiment}")

    return sentiment_dict  # Zwraca s≈Çownik {Symbol: Sentyment}

def get_sentiment(news_topic="stocks"):
    """G≈Ç√≥wna funkcja pobierania i analizy sentymentu news√≥w"""
    news_articles = fetch_news(news_topic)
    sentiment_score = analyze_sentiment(news_articles)
    return sentiment_score  # Warto≈õƒá miƒôdzy -1 a 1

